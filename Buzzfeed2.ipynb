{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "script_words = {}\n",
    "\n",
    "def read_text(movie):\n",
    "    textline = []\n",
    "    textname = movie+'.txt'\n",
    "    lines = open(textname,'r').readlines()\n",
    "    for line in lines:\n",
    "        textline.append(line.strip())\n",
    "    return textline\n",
    "\n",
    "#'the-godfather'\n",
    "#'the-fault-in-our-stars'\n",
    "file_names = ['the-godfather','the-hangover','the-lord-of-the-rings','star-wars','ghostbusters']\n",
    "for movie in file_names:\n",
    "    script_words[movie] = read_text(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en')\n",
    "def named_entity_counts(document,named_entity_label):   \n",
    "    ## Function that outputs a Counter object of human entities found\\n\",\n",
    "    occurrences = [ent.string.strip() for ent in document.ents if ent.label_ == named_entity_label and ent.string.strip()]\n",
    "    return Counter(occurrences)\n",
    "\n",
    "def parse_text(movie):\n",
    "    name_text = movie + '.txt'\n",
    "    text2 = open(name_text).read()\n",
    "    doc = nlp(text2)\n",
    "    parsed_script = doc  \n",
    "    entity_type = 'PERSON' \n",
    "    number_of_entities = 5\n",
    "    Entities=pd.DataFrame(named_entity_counts(parsed_script,entity_type).most_common(number_of_entities),columns=[\"Character\",\"Count\"])\n",
    "    Entities['Movie'] = movie\n",
    "    return Entities\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for file in file_names:\n",
    "    df = parse_text(file)\n",
    "    result = result.append(df,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_names (Character):\n",
    "    name_dict = {}\n",
    "    for character in Character:\n",
    "        character = character.upper()\n",
    "        if (character in name_dict.keys()):\n",
    "            continue\n",
    "        if len(character.split()) >=2:\n",
    "            full_name = character.split()\n",
    "            name_dict[full_name[0]] = character\n",
    "        else:\n",
    "            name_dict[character] = ''\n",
    "    return name_dict\n",
    "\n",
    "dictionary_names = dict_names (result['Character'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MICHAEL': 'the-godfather', 'KAY': 'the-godfather', 'SONNY': 'the-godfather', 'MIKE': 'the-godfather', 'VICK': 'the-hangover', 'ALAN': 'the-hangover', 'DOUG': 'the-hangover', 'GANDALF': 'the-lord-of-the-rings', 'SAM': 'the-lord-of-the-rings', 'BOROMIR': 'the-lord-of-the-rings', 'ARAGORN': 'the-lord-of-the-rings', 'FRODO': 'the-lord-of-the-rings', 'LUKE': 'star-wars', 'CHEWIE': 'star-wars', 'LEIA': 'star-wars', 'VADER': 'star-wars', 'LANDO': 'star-wars', 'VENKMAN': 'ghostbusters', 'SPENGLER': 'ghostbusters', 'STANTZ': 'ghostbusters', 'DANA': 'ghostbusters'}\n"
     ]
    }
   ],
   "source": [
    "name_movie = result.set_index('Character').to_dict()['Movie']\n",
    "name_movie2 = {}\n",
    "for name in dictionary_names.keys():\n",
    "    for n in name_movie.keys():\n",
    "        if name in n.upper():\n",
    "            name_movie2[name] = name_movie[n]   \n",
    "print (name_movie2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_says (textlist,character):\n",
    "    sublist = []\n",
    "    words_list = []\n",
    "    for i in range(len(textlist)):\n",
    "        if (textlist[i].strip() == character):\n",
    "            j = i + 1\n",
    "            while (textlist[j]!= ''):\n",
    "                j += 1\n",
    "            sublist.append(textlist[i+1:j])\n",
    "    words_list.append(sublist)\n",
    "#     for character in dictionary_names.values():\n",
    "#         if character != '':\n",
    "#             for i in range(len(textlist)):\n",
    "#                 if (textlist[i].strip() == character):\n",
    "#                     j = i + 1\n",
    "#                     while (textlist[j]!= ''):\n",
    "#                         j += 1\n",
    "#                     sublist.append(textlist[i:j])\n",
    "#         words_list.append(sublist)\n",
    "    return words_list\n",
    "def char_names (movie):\n",
    "    n = []\n",
    "    for name in name_movie2:\n",
    "        if name_movie2[name] == movie:\n",
    "            n.append(name)\n",
    "    return n\n",
    "\n",
    "for movie in file_names:\n",
    "    for name in char_names(movie):\n",
    "        file_name = name+'.txt'\n",
    "        file = open(file_name,\"w\")\n",
    "        file.write(str(people_says(script_words[movie],name)))\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'text/plain;charset=utf-8',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('version', '2017-10-13'),\n",
    ")\n",
    "\n",
    "def json_parser(text_name):\n",
    "    data = open(text_name, 'rb').read()\n",
    "    response = requests.post('https://gateway.watsonplatform.net/personality-insights/api/v3/profile?version=2017-10-13', headers=headers, data=data, auth=('apikey', 'QoK4TRsFxHfWUW3d-_KV4DOujgALshtnrzPolJ6BY_Wk'))\n",
    "    parsed = json.loads(response.text)\n",
    "\n",
    "    trait_dict = {}\n",
    "\n",
    "    for i in range(len(parsed)-2):\n",
    "        trait_dict[(parsed['personality'][i]['name'])] = parsed['personality'][i]['percentile']\n",
    "\n",
    "        for j in (range(len(parsed['personality'][i]['children']))):\n",
    "            trait_dict[(parsed['personality'][i]['children'][j]['name'])] = parsed['personality'][i]['children'][j]['percentile']\n",
    "    return trait_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality = []\n",
    "#if re-run the function again, need to un-comment these below\n",
    "dictionary_names.pop('MIKE')\n",
    "dictionary_names.pop('CHEWIE')\n",
    "for name in dictionary_names.keys():\n",
    "    txtname = name + '.txt'\n",
    "    personality.append(json_parser(txtname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Openness': 0.6668404703601938, 'Adventurousness': 0.6260163913012967, 'Artistic interests': 0.8292338604025926, 'Emotionality': 0.868171554277269, 'Imagination': 0.515258370209555, 'Intellect': 0.894137450419284, 'Authority-challenging': 0.7824883857619294, 'Conscientiousness': 0.07739835450047117, 'Achievement striving': 0.11765954715738786, 'Cautiousness': 0.35502692063746916, 'Dutifulness': 0.49068453721787547, 'Orderliness': 0.024861534752686487, 'Self-discipline': 0.06621083212007167, 'Self-efficacy': 0.018492766016342477, 'Extraversion': 0.043006513587015904, 'Activity level': 0.09351802647904073, 'Assertiveness': 0.057039389341209557, 'Cheerfulness': 0.36552781876614127, 'Excitement-seeking': 0.4064231286171068, 'Outgoing': 0.13432000539303723, 'Gregariousness': 0.10417964210216413, 'Agreeableness': 0.8413594454534471, 'Altruism': 0.7932500239774689, 'Cooperation': 0.8231764007678126, 'Modesty': 0.9927479558802288, 'Uncompromising': 0.9361858342634223, 'Sympathy': 0.9000174593169584, 'Trust': 0.20974352479888453, 'Emotional range': 0.09131399933306378, 'Fiery': 0.2875887085365074, 'Prone to worry': 0.7291254429535683, 'Melancholy': 0.9500736355547122, 'Immoderation': 0.770362889131047, 'Self-consciousness': 0.7714927698506757, 'Susceptible to stress': 0.8809833184397444}\n",
      "{'Openness': 0.9523556904241322, 'Adventurousness': 0.7793105540973451, 'Artistic interests': 0.863621866466676, 'Emotionality': 0.6939666757360586, 'Imagination': 0.8174103041913683, 'Intellect': 0.9952512882784331, 'Authority-challenging': 0.947037846458409, 'Conscientiousness': 0.14130471938291506, 'Achievement striving': 0.4381325616886916, 'Cautiousness': 0.8143635432363271, 'Dutifulness': 0.45081001335991044, 'Orderliness': 0.35204148357790727, 'Self-discipline': 0.22587014973629654, 'Self-efficacy': 0.4099995641220245, 'Extraversion': 0.1514823290274146, 'Activity level': 0.25576120899652344, 'Assertiveness': 0.42713811489437736, 'Cheerfulness': 0.06863462436063078, 'Excitement-seeking': 0.2698880886111907, 'Outgoing': 0.05091952645790587, 'Gregariousness': 0.005535529637831826, 'Agreeableness': 0.1496167218848014, 'Altruism': 0.6810510837030674, 'Cooperation': 0.5973293510937049, 'Modesty': 0.6417267958638091, 'Uncompromising': 0.7928610621857162, 'Sympathy': 0.9004009456563757, 'Trust': 0.2806269111981907}\n",
      "{'Openness': 0.9315051729108534, 'Adventurousness': 0.8002221786888133, 'Artistic interests': 0.8324633021914184, 'Emotionality': 0.5542829844781801, 'Imagination': 0.8128651971565807, 'Intellect': 0.9974137306709506, 'Authority-challenging': 0.9697628411961203, 'Conscientiousness': 0.23222816397412188, 'Achievement striving': 0.47735842405842854, 'Cautiousness': 0.8052125923987166, 'Dutifulness': 0.3263478035992865, 'Orderliness': 0.3880000934994017, 'Self-discipline': 0.1968331442899927, 'Self-efficacy': 0.41529636018830646, 'Extraversion': 0.15167476733443647, 'Activity level': 0.3382318689042949, 'Assertiveness': 0.5180204185175988, 'Cheerfulness': 0.11520738641827694, 'Excitement-seeking': 0.265258724798389, 'Outgoing': 0.1557438596508784, 'Gregariousness': 0.06729703199932158, 'Agreeableness': 0.055649122651063754, 'Altruism': 0.47673957383564525, 'Cooperation': 0.5786168385368062, 'Modesty': 0.4005826427532121, 'Uncompromising': 0.7822047921027568, 'Sympathy': 0.9006212764792594, 'Trust': 0.4513927860651238}\n",
      "{'Openness': 0.8113613491658862, 'Adventurousness': 0.8035874407710976, 'Artistic interests': 0.6779780094033505, 'Emotionality': 0.6056910091616986, 'Imagination': 0.6483511867823273, 'Intellect': 0.946349986570714, 'Authority-challenging': 0.6650691625121887, 'Conscientiousness': 0.2656897609455323, 'Achievement striving': 0.5175939627325692, 'Cautiousness': 0.5490465360191159, 'Dutifulness': 0.41733514107104647, 'Orderliness': 0.41117662103611824, 'Self-discipline': 0.28627102587933306, 'Self-efficacy': 0.546016226863177, 'Extraversion': 0.2274901387912477, 'Activity level': 0.2917556487446056, 'Assertiveness': 0.5544025551194709, 'Cheerfulness': 0.31334688450105824, 'Excitement-seeking': 0.3462386163404414, 'Outgoing': 0.2513314508862333, 'Gregariousness': 0.13925590020422973, 'Agreeableness': 0.5415657328933317, 'Altruism': 0.6567607630344476, 'Cooperation': 0.583530027890023, 'Modesty': 0.6646479244306933, 'Uncompromising': 0.9113694026715468, 'Sympathy': 0.8617478621310922, 'Trust': 0.2711708395439437}\n"
     ]
    }
   ],
   "source": [
    "from cloudant import cloudant_iam,query\n",
    "\n",
    "# Authenticate using an IAM API key\n",
    "ACCOUNT_NAME = '9f18399f-0e0a-4464-9cae-afcc09328dbe-bluemix'\n",
    "API_KEY = 'j7H-txptJqOJ9G1PQ01hIHZYcs2oieznEkt6qWvGQBio'\n",
    "DB_NAME = 'elmo_characters'\n",
    "\n",
    "def put_character(db, **kargs):\n",
    "    db.create_document(kargs)\n",
    "\n",
    "def get_character(db, c_id):\n",
    "    return db[c_id]\n",
    "\n",
    "def get_character_id(movie, character):\n",
    "   return \":\".join([movie.lower(), character.lower()])\n",
    "\n",
    "def search(db, movie, lmt = 10):\n",
    "    qr = query.Query(db, selector={\"movie\": movie})\n",
    "    return list(qr(limit = lmt)['docs'])\n",
    "\n",
    "def connect_db():\n",
    "    client = cloudant_iam(ACCOUNT_NAME, API_KEY, connect=True)\n",
    "    db_session = client.session()\n",
    "    if not DB_NAME in client.all_dbs():\n",
    "        db = client.create_database(DB_NAME)\n",
    "\n",
    "    if not db.exists():\n",
    "        return None\n",
    "\n",
    "    return client[DB_NAME]\n",
    "\n",
    "def search_movie(movie):\n",
    "    with cloudant_iam(ACCOUNT_NAME, API_KEY, connect=True) as client:\n",
    "        db = None\n",
    "        if not DB_NAME in client.all_dbs():\n",
    "            db = client.create_database(DB_NAME)\n",
    "        else:\n",
    "            db = client[DB_NAME]\n",
    "            \n",
    "        movie = movie.strip()\n",
    "        return search(db, movie.replace(' ', '-')) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    with cloudant_iam(ACCOUNT_NAME, API_KEY, connect=True) as client:\n",
    "        db = None\n",
    "        dblist = client.all_dbs()\n",
    "    \n",
    "        if not DB_NAME in dblist:\n",
    "            db = client.create_database(DB_NAME)\n",
    "        else:\n",
    "            db = client[DB_NAME] \n",
    "        \n",
    "        for name in dictionary_names.keys():\n",
    "            \n",
    "            txtname = name + '.txt'\n",
    "            c_id = get_character_id(name_movie2[name], name)\n",
    "            put_character(db, _id=c_id, movie = name_movie2[name],character=name, personality=json_parser(txtname))\n",
    "        \n",
    "        for doc in search_movie('ghostbusters'):\n",
    "            print (doc['personality'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"session_id\": \"6df6f0e6-5091-4b78-9ed8-131c057e12d6\"\n",
      "}\n",
      "Elmo: What state or country do you never want to go back to?\n",
      "Me: switch movie\n",
      "Input your movie: ghostbusters\n",
      "You switched to ghostbusters\n",
      "Elmo: Bingo! this is it.\n",
      "Me: coding\n",
      "Elmo: What job would you be terrible at?\n",
      "Me: coding\n",
      "Elmo: If you didn’t have to sleep, what would you do with the extra time?\n",
      "Me: coding\n",
      "Elmo: What do you consider to be your best find?\n",
      "Me: coding\n",
      "Elmo: Who’s your go to band or artist when you can’t decide on something to listen to?\n",
      "Me: coding\n",
      "Elmo: What’s the best single day on the calendar?\n",
      "Me: coding\n",
      "Elmo: I didn't understand. You can try rephrasing.\n",
      "Me: coding\n",
      "Elmo: Who has impressed you most with what they’ve accomplished?\n",
      "Me: coding\n",
      "Elmo: What would be your ideal way to spend the weekend?\n",
      "Me: coding\n",
      "Elmo: What is the most annoying habit that other people have?\n",
      "Me: coding\n",
      "Elmo: What fictional place would you most like to go?\n",
      "Me: coding\n",
      "Elmo: What would be your first question after waking up from being cryogenically frozen for 100 years?\n",
      "Me: coding\n",
      "Elmo: What pets did you have while you were growing up?\n",
      "Me: coding\n",
      "Elmo: What would be the most amazing adventure to go on?\n",
      "Me: coding\n",
      "Elmo: What do you wish you knew more about?\n",
      "Me: coding\n",
      "Elmo: When was the last time you climbed a tree?\n",
      "Me: coding\n",
      "Elmo: What are some small things that make your day better?\n",
      "Me: coding\n",
      "Elmo: How often do you play sports?\n",
      "Me: coding\n",
      "Elmo: I didn't get your meaning.\n",
      "Me: coding\n",
      "Elmo: How often do you people watch?\n",
      "Me: coding\n",
      "Elmo: What TV show or movie do you refuse to watch?\n",
      "Me: coding\n",
      "Elmo: What would your perfect room look like?\n",
      "Me: coding\n",
      "Elmo: What’s your claim to fame?\n",
      "Me: match character\n",
      "You are most like \n",
      "4\n",
      "Elmo: SPENGLER\n",
      "Me: bye\n",
      "Elmo: Bye\n",
      "Me: bye\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "import json, uuid\n",
    "from ibm_watson import AssistantV2\n",
    "NUMBER_OF_TRAITS = 28\n",
    "\n",
    "def least_squares_matcher(chatbot_percentiles, list_of_percentiles,movie_characters):\n",
    "    least_squares = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    print (len(list_of_percentiles))\n",
    "    while j < len(list_of_percentiles):\n",
    "        cur_least_square = 0\n",
    "        \n",
    "        while i < 10: \n",
    "            \n",
    "            diff = chatbot_percentiles[i] - list_of_percentiles[j][i]\n",
    "            square = diff * diff\n",
    "            cur_least_square += square\n",
    "            i += 1\n",
    "\n",
    "        least_squares.append(cur_least_square)\n",
    "        j += 1\n",
    "    \n",
    "\n",
    "    least_square_index = (least_squares.index(min(least_squares)))\n",
    "\n",
    "    return (movie_characters[least_square_index])\n",
    "        \n",
    "\n",
    "def load_credential(authfile = None):\n",
    "    if authfile == None:\n",
    "        authfile = 'ibm-credentials.env'\n",
    "\n",
    "    with open(authfile) as f:\n",
    "        cred = {}\n",
    "        for line in f:\n",
    "            parts = line.strip('\\r').strip('\\n').split(\"=\")\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                cred[parts[0]] = parts[1]\n",
    "        return cred;\n",
    "\n",
    "    return None\n",
    "\n",
    "def create_elmo(credential):\n",
    "   # If service instance provides API key authentication\n",
    "   return AssistantV2(\n",
    "              version='2018-09-20',\n",
    "              # url is optional, and defaults to the URL below. Use the correct URL for your region.\n",
    "              url='https://gateway.watsonplatform.net/assistant/api',\n",
    "              iam_apikey=credential['ASSISTANT_IAM_APIKEY'])\n",
    "\n",
    "#########################\n",
    "# Sessions\n",
    "#########################\n",
    "def create_session(assistant, ass_id):\n",
    "    session = assistant.create_session(ass_id).get_result()\n",
    "    print(json.dumps(session, indent=2))\n",
    "    return session\n",
    "\n",
    "#########################\n",
    "# Message\n",
    "#########################\n",
    "def send_message(assistant, ass_id, sess_id, msg):\n",
    "    message = assistant.message(\n",
    "    ass_id,\n",
    "    sess_id,\n",
    "    input={'text': msg}, #'What\\'s the weather like?'},\n",
    "    context={'metadata': {'deployment': 'myDeployment'\n",
    "           }\n",
    "       }).get_result()\n",
    "   #print(json.dumps(message, indent=2))\n",
    "    return message['output']['generic'][0]['text']\n",
    "\n",
    "def delete_session(assistant, ass_id, sess_id):\n",
    "    return assistant.delete_session(ass_id, sess_id).get_result()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    credential = load_credential()\n",
    "    \n",
    "    if not credential:\n",
    "        pass\n",
    "\n",
    "    elmo = create_elmo(credential)\n",
    "    ass_id = \"70f87349-4762-41fb-a263-5dfc9626ad53\"\n",
    "    sess_id = create_session(elmo, ass_id)[\"session_id\"]\n",
    "\n",
    "    history = []\n",
    "    dialog = \"hello\"\n",
    "    msg = \"\"\n",
    "    movie = \"the-godfather\"\n",
    "    movie_characters = []\n",
    "\n",
    "   #CHATBOT STRUCTURES\n",
    "    chatbot_dict = {} #dictionary of traits->percentiles for user conversation with chatbot\n",
    "    chatbot_percentiles = []  #list of percentiles for user conversation with chatbot\n",
    "\n",
    "   #MOVIE CHARACTER STRUCTURES\n",
    "    list_of_dicts = []  #list of dictionaries of traits->percentiles (dictionary is for each character)\n",
    "    list_of_percentiles = []  #list of lists of percentiles (list is for each character)\n",
    "    smaller_list = [] #for parsing purposes\n",
    "    movie_characters = []\n",
    "\n",
    "\n",
    "    while not \"bye\" in msg.lower() and not \"see you\" in msg.lower():\n",
    "        msg = send_message(elmo, ass_id, sess_id, dialog)\n",
    "        history.append(msg)\n",
    "        \n",
    "        if \"Bingo! this is it\" in msg:\n",
    "            movie = input(\"Input your movie: \") #history[-1].split(\"movie\")[1].strip()\n",
    "            print(\"You switched to\", movie)\n",
    "            movie_characters = char_names(movie)\n",
    "            #history.append(msg)\n",
    "            \n",
    "        \n",
    "        elif \"Character\" in msg or \"Match character\" in msg or \"Search character\" in msg:\n",
    "            if len(movie_characters)  == 0:\n",
    "                movie_characters = char_names(movie)\n",
    "\n",
    "            import json\n",
    "            import requests\n",
    "\n",
    "            headers = {'Content-Type': 'text/plain;charset=utf-8','Accept': 'application/json',}\n",
    "\n",
    "            params = (('version', '2017-10-13'),)\n",
    "\n",
    "            data = open('history.txt', 'rb').read()\n",
    "            response = requests.post('https://gateway.watsonplatform.net/personality-insights/api/v3/profile?version=2017-10-13', headers=headers, data=data, auth=('apikey', 'QoK4TRsFxHfWUW3d-_KV4DOujgALshtnrzPolJ6BY_Wk'))\n",
    "            parsed = json.loads(response.text)\n",
    "\n",
    "           #parses through chatbot dictionary traits->percentiles to generate list of percentiles \n",
    "            for i in range(len(parsed)-2):\n",
    "                chatbot_dict[(parsed['personality'][i]['name'])] = parsed['personality'][i]['percentile']\n",
    " \n",
    "            for j in (range(len(parsed['personality'][i]['children']))):\n",
    "               chatbot_dict[(parsed['personality'][i]['children'][j]['name'])] = parsed['personality'][i]['children'][j]['percentile']\n",
    "\n",
    "            for trait in chatbot_dict:\n",
    "                chatbot_percentiles.append(chatbot_dict[trait])\n",
    "            \n",
    "            for doc in search_movie(movie):\n",
    "                list_of_dicts.append(doc['personality'])\n",
    "\n",
    "            for item in list_of_dicts:\n",
    "                for trait in item:\n",
    "                    smaller_list.append(item[trait])  \n",
    "                list_of_percentiles.append(smaller_list)\n",
    "                smaller_list=[]\n",
    "            \n",
    "            print ('You are most like ')\n",
    "            msg = least_squares_matcher(chatbot_percentiles, list_of_percentiles,movie_characters)\n",
    "\n",
    "\n",
    "\n",
    "           # do the personal insights/api/v3/profile# find the best character\n",
    "        dialog = input(\"Elmo: %s\\nMe: \" %(msg.strip('\\r').strip('\\n')))\n",
    "        history.append(dialog)\n",
    "\n",
    "        file_name = 'history'+'.txt'\n",
    "        file = open(file_name,\"w\")\n",
    "        file.write(str(history))\n",
    "        file.close()\n",
    "\n",
    "    delete_session(elmo, ass_id, sess_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"session_id\": \"510e9965-5ef5-42db-bb5b-1173fe1d2532\"\n",
      "}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'send_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3e6641fd7c68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m    \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m    \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m\"bye\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m\"see you\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m        \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melmo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mass_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m        \u001b[0mdialog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Elmo: %s\\nMe: \"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'send_message' is not defined"
     ]
    }
   ],
   "source": [
    "codingcodingcodingcodingcodingcodingcodingcodingcodingcodingcoding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
