{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "script_words = {}\n",
    "\n",
    "def read_text(movie):\n",
    "    textline = []\n",
    "    textname = movie+'.txt'\n",
    "    lines = open(textname,'r').readlines()\n",
    "    for line in lines:\n",
    "        textline.append(line.strip())\n",
    "    return textline\n",
    "\n",
    "#'the-godfather'\n",
    "#'the-fault-in-our-stars'\n",
    "file_names = ['the-godfather','the-hangover','the-lord-of-the-rings','star-wars','ghostbusters']\n",
    "for movie in file_names:\n",
    "    script_words[movie] = read_text(movie)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from collections import Counter\n",
    "nlp = spacy.load('en')\n",
    "def named_entity_counts(document,named_entity_label):   \n",
    "    ## Function that outputs a Counter object of human entities found\\n\",\n",
    "    occurrences = [ent.string.strip() for ent in document.ents if ent.label_ == named_entity_label and ent.string.strip()]\n",
    "    return Counter(occurrences)\n",
    "\n",
    "def parse_text(movie):\n",
    "    name_text = movie + '.txt'\n",
    "    text2 = open(name_text).read()\n",
    "    doc = nlp(text2)\n",
    "    parsed_script = doc  \n",
    "    entity_type = 'PERSON' \n",
    "    number_of_entities = 5\n",
    "    Entities=pd.DataFrame(named_entity_counts(parsed_script,entity_type).most_common(number_of_entities),columns=[\"Character\",\"Count\"])\n",
    "    Entities['Movie'] = movie\n",
    "    return Entities\n",
    "\n",
    "result = pd.DataFrame()\n",
    "for file in file_names:\n",
    "    df = parse_text(file)\n",
    "    result = result.append(df,ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dict_names (Character):\n",
    "    name_dict = {}\n",
    "    for character in Character:\n",
    "        character = character.upper()\n",
    "        if (character in name_dict.keys()):\n",
    "            continue\n",
    "        if len(character.split()) >=2:\n",
    "            full_name = character.split()\n",
    "            name_dict[full_name[0]] = character\n",
    "        else:\n",
    "            name_dict[character] = ''\n",
    "    return name_dict\n",
    "\n",
    "dictionary_names = dict_names (result['Character'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'MICHAEL': 'the-godfather', 'KAY': 'the-godfather', 'SONNY': 'the-godfather', 'MIKE': 'the-godfather', 'VICK': 'the-hangover', 'ALAN': 'the-hangover', 'DOUG': 'the-hangover', 'GANDALF': 'the-lord-of-the-rings', 'SAM': 'the-lord-of-the-rings', 'BOROMIR': 'the-lord-of-the-rings', 'ARAGORN': 'the-lord-of-the-rings', 'FRODO': 'the-lord-of-the-rings', 'LUKE': 'star-wars', 'CHEWIE': 'star-wars', 'LEIA': 'star-wars', 'VADER': 'star-wars', 'LANDO': 'star-wars', 'VENKMAN': 'ghostbusters', 'SPENGLER': 'ghostbusters', 'STANTZ': 'ghostbusters', 'DANA': 'ghostbusters'}\n"
     ]
    }
   ],
   "source": [
    "name_movie = result.set_index('Character').to_dict()['Movie']\n",
    "name_movie2 = {}\n",
    "for name in dictionary_names.keys():\n",
    "    for n in name_movie.keys():\n",
    "        if name in n.upper():\n",
    "            name_movie2[name] = name_movie[n]   \n",
    "print (name_movie2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def people_says (textlist,character):\n",
    "    sublist = []\n",
    "    words_list = []\n",
    "    for i in range(len(textlist)):\n",
    "        if (textlist[i].strip() == character):\n",
    "            j = i + 1\n",
    "            while (textlist[j]!= ''):\n",
    "                j += 1\n",
    "            sublist.append(textlist[i+1:j])\n",
    "    words_list.append(sublist)\n",
    "#     for character in dictionary_names.values():\n",
    "#         if character != '':\n",
    "#             for i in range(len(textlist)):\n",
    "#                 if (textlist[i].strip() == character):\n",
    "#                     j = i + 1\n",
    "#                     while (textlist[j]!= ''):\n",
    "#                         j += 1\n",
    "#                     sublist.append(textlist[i:j])\n",
    "#         words_list.append(sublist)\n",
    "    return words_list\n",
    "def char_names (movie):\n",
    "    n = []\n",
    "    for name in name_movie2:\n",
    "        if name_movie2[name] == movie:\n",
    "            n.append(name)\n",
    "    return n\n",
    "\n",
    "for movie in file_names:\n",
    "    for name in char_names(movie):\n",
    "        file_name = name+'.txt'\n",
    "        file = open(file_name,\"w\")\n",
    "        file.write(str(people_says(script_words[movie],name)))\n",
    "file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "\n",
    "headers = {\n",
    "    'Content-Type': 'text/plain;charset=utf-8',\n",
    "    'Accept': 'application/json',\n",
    "}\n",
    "\n",
    "params = (\n",
    "    ('version', '2017-10-13'),\n",
    ")\n",
    "\n",
    "def json_parser(text_name):\n",
    "    data = open(text_name, 'rb').read()\n",
    "    response = requests.post('https://gateway.watsonplatform.net/personality-insights/api/v3/profile?version=2017-10-13', headers=headers, data=data, auth=('apikey', 'QoK4TRsFxHfWUW3d-_KV4DOujgALshtnrzPolJ6BY_Wk'))\n",
    "    parsed = json.loads(response.text)\n",
    "\n",
    "    trait_dict = {}\n",
    "\n",
    "    for i in range(len(parsed)-2):\n",
    "        trait_dict[(parsed['personality'][i]['name'])] = parsed['personality'][i]['percentile']\n",
    "\n",
    "        for j in (range(len(parsed['personality'][i]['children']))):\n",
    "            trait_dict[(parsed['personality'][i]['children'][j]['name'])] = parsed['personality'][i]['children'][j]['percentile']\n",
    "    return trait_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "personality = []\n",
    "#if re-run the function again, need to un-comment these below\n",
    "dictionary_names.pop('MIKE')\n",
    "dictionary_names.pop('CHEWIE')\n",
    "for name in dictionary_names.keys():\n",
    "    txtname = name + '.txt'\n",
    "    personality.append(json_parser(txtname))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Openness': 0.9119848877026207, 'Adventurousness': 0.6038497217061395, 'Artistic interests': 0.9578941990319867, 'Emotionality': 0.7027423921357344, 'Imagination': 0.9634975651268665, 'Intellect': 0.9822857010520005, 'Authority-challenging': 0.33348480428548877, 'Conscientiousness': 0.41462612078798344, 'Achievement striving': 0.6811621180787211, 'Cautiousness': 0.5230057936924101, 'Dutifulness': 0.39375873560838437, 'Orderliness': 0.5042439682599319, 'Self-discipline': 0.413560533230124, 'Self-efficacy': 0.5858992544355176, 'Extraversion': 0.07263553593037803, 'Activity level': 0.505002270118807, 'Assertiveness': 0.4857583572660254, 'Cheerfulness': 0.362725520684789, 'Excitement-seeking': 0.6093242713415268, 'Outgoing': 0.08471101750022664, 'Gregariousness': 0.012041229932974795, 'Agreeableness': 0.09243758234351301, 'Altruism': 0.7112220356523786, 'Cooperation': 0.22203802713402698, 'Modesty': 0.9206981101165445, 'Uncompromising': 0.8071769103671835, 'Sympathy': 0.98054449254638, 'Trust': 0.16990442539501494, 'Emotional range': 0.46615506975142784, 'Fiery': 0.4633364717841275, 'Prone to worry': 0.31468171862149774, 'Melancholy': 0.8196805521332287, 'Immoderation': 0.12851716815115827, 'Self-consciousness': 0.6725427694080949, 'Susceptible to stress': 0.37033104021839897}\n",
      "{'Openness': 0.9896338281153159, 'Adventurousness': 0.3838770812532539, 'Artistic interests': 0.9766429776999493, 'Emotionality': 0.9219351802212027, 'Imagination': 0.9427438007769114, 'Intellect': 0.9985255405179133, 'Authority-challenging': 0.5010704011281433, 'Conscientiousness': 0.6659185778371797, 'Achievement striving': 0.4842133695225342, 'Cautiousness': 0.6808580144029849, 'Dutifulness': 0.7095269561058255, 'Orderliness': 0.4878363059100984, 'Self-discipline': 0.2927600575122848, 'Self-efficacy': 0.3482191086305926, 'Extraversion': 0.031427462821396523, 'Activity level': 0.3443381798367149, 'Assertiveness': 0.41178397251472276, 'Cheerfulness': 0.18640360848683707, 'Excitement-seeking': 0.3263824124359599, 'Outgoing': 0.09443559631259107, 'Gregariousness': 0.02112250197745419, 'Agreeableness': 0.09975014322397635, 'Altruism': 0.9116652861453332, 'Cooperation': 0.5074759654243607, 'Modesty': 0.9589698878760982, 'Uncompromising': 0.9378055415233275, 'Sympathy': 0.9853757221921995, 'Trust': 0.2202808920765898, 'Emotional range': 0.7342008909247182, 'Fiery': 0.20777793415769147, 'Prone to worry': 0.3079978428977034, 'Melancholy': 0.8023037243779808, 'Immoderation': 0.27074750725747887, 'Self-consciousness': 0.6386150522588618, 'Susceptible to stress': 0.41314982474296175}\n",
      "{'Openness': 0.829835846520723, 'Adventurousness': 0.8247321528405069, 'Artistic interests': 0.9468436833985401, 'Emotionality': 0.8300090300590074, 'Imagination': 0.8369140344687251, 'Intellect': 0.9872875922240314, 'Authority-challenging': 0.6853893535569342, 'Conscientiousness': 0.1536863173903531, 'Achievement striving': 0.3152291751929258, 'Cautiousness': 0.6989094474680386, 'Dutifulness': 0.6388909092903604, 'Orderliness': 0.13537607679772512, 'Self-discipline': 0.1058624985902073, 'Self-efficacy': 0.08638690389947568, 'Extraversion': 0.00600862308398159, 'Activity level': 0.10595868705441214, 'Assertiveness': 0.18270800251976793, 'Cheerfulness': 0.34230695125740124, 'Excitement-seeking': 0.3723317939753593, 'Outgoing': 0.054771613143058784, 'Gregariousness': 0.07432857489610623, 'Agreeableness': 0.41702345764925586, 'Altruism': 0.874024682921341, 'Cooperation': 0.7676822209811779, 'Modesty': 0.9889370008062922, 'Uncompromising': 0.9594666219584527, 'Sympathy': 0.9892477593454915, 'Trust': 0.3127559751788269}\n",
      "{'Openness': 0.9909211224371676, 'Adventurousness': 0.4092880906958712, 'Artistic interests': 0.9758583928915587, 'Emotionality': 0.8498536411347111, 'Imagination': 0.978295964255173, 'Intellect': 0.9990741913939156, 'Authority-challenging': 0.6537284027492462, 'Conscientiousness': 0.2689313472162025, 'Achievement striving': 0.27806549414955795, 'Cautiousness': 0.5235862161944747, 'Dutifulness': 0.6117514342262409, 'Orderliness': 0.2649047243036834, 'Self-discipline': 0.09116924266884513, 'Self-efficacy': 0.2597389387407094, 'Extraversion': 0.01359526498135133, 'Activity level': 0.17551431681832624, 'Assertiveness': 0.31424198668270215, 'Cheerfulness': 0.08119644601200093, 'Excitement-seeking': 0.3876321389377912, 'Outgoing': 0.033636559256913556, 'Gregariousness': 0.0050532339374556035, 'Agreeableness': 0.08939859048554838, 'Altruism': 0.8871530789008035, 'Cooperation': 0.5127967884066111, 'Modesty': 0.8967129851884967, 'Uncompromising': 0.7733559947323152, 'Sympathy': 0.989737141202558, 'Trust': 0.23385666631862545}\n",
      "{'Openness': 0.6726327473964998, 'Adventurousness': 0.16178276915766127, 'Artistic interests': 0.8389272874756344, 'Emotionality': 0.7372857221400313, 'Imagination': 0.9497607801347093, 'Intellect': 0.9313958642019895, 'Authority-challenging': 0.7076966328443894, 'Conscientiousness': 0.012202864578123473, 'Achievement striving': 0.05594068483827036, 'Cautiousness': 0.13484599753108034, 'Dutifulness': 0.19469148846999856, 'Orderliness': 0.04482253519314888, 'Self-discipline': 0.0010838538995638913, 'Self-efficacy': 0.03626550006249224, 'Extraversion': 0.00315654109442276, 'Activity level': 0.015608201699646329, 'Assertiveness': 0.09992364834129808, 'Cheerfulness': 0.1776747681812484, 'Excitement-seeking': 0.5632841474336462, 'Outgoing': 0.013229152785902254, 'Gregariousness': 0.04864482419856281, 'Agreeableness': 0.14279861178169562, 'Altruism': 0.7278484496612762, 'Cooperation': 0.27727783576942944, 'Modesty': 0.9505089593884932, 'Uncompromising': 0.32928323071760024, 'Sympathy': 0.9543033059745296, 'Trust': 0.15747486827113893, 'Emotional range': 0.06402637057601374, 'Fiery': 0.7229664961104795, 'Prone to worry': 0.7872369351948448, 'Melancholy': 0.9971266968397974, 'Immoderation': 0.7580464843496059, 'Self-consciousness': 0.9545286076513477, 'Susceptible to stress': 0.8121794412148902}\n"
     ]
    }
   ],
   "source": [
    "from cloudant import cloudant_iam,query\n",
    "\n",
    "# Authenticate using an IAM API key\n",
    "ACCOUNT_NAME = '9f18399f-0e0a-4464-9cae-afcc09328dbe-bluemix'\n",
    "API_KEY = 'j7H-txptJqOJ9G1PQ01hIHZYcs2oieznEkt6qWvGQBio'\n",
    "DB_NAME = 'elmo_characters'\n",
    "\n",
    "def put_character(db, **kargs):\n",
    "    db.create_document(kargs)\n",
    "\n",
    "def get_character(db, c_id):\n",
    "    return db[c_id]\n",
    "\n",
    "def get_character_id(movie, character):\n",
    "   return \":\".join([movie.lower(), character.lower()])\n",
    "\n",
    "def search(db, movie, lmt = 10):\n",
    "    qr = query.Query(db, selector={\"movie\": movie})\n",
    "    return list(qr(limit = lmt)['docs'])\n",
    "\n",
    "def connect_db():\n",
    "    client = cloudant_iam(ACCOUNT_NAME, API_KEY, connect=True)\n",
    "    db_session = client.session()\n",
    "    if not DB_NAME in client.all_dbs():\n",
    "        db = client.create_database(DB_NAME)\n",
    "\n",
    "    if not db.exists():\n",
    "        return None\n",
    "\n",
    "    return client[DB_NAME]\n",
    "\n",
    "def search_movie(movie):\n",
    "    with cloudant_iam(ACCOUNT_NAME, API_KEY, connect=True) as client:\n",
    "        db = None\n",
    "        if not DB_NAME in client.all_dbs():\n",
    "            db = client.create_database(DB_NAME)\n",
    "        else:\n",
    "            db = client[DB_NAME]\n",
    "            \n",
    "        movie = movie.strip()\n",
    "        return search(db, movie.replace(' ', '-')) \n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    with cloudant_iam(ACCOUNT_NAME, API_KEY, connect=True) as client:\n",
    "        db = None\n",
    "        dblist = client.all_dbs()\n",
    "    \n",
    "        if not DB_NAME in dblist:\n",
    "            db = client.create_database(DB_NAME)\n",
    "        else:\n",
    "            db = client[DB_NAME] \n",
    "        \n",
    "        for name in dictionary_names.keys():\n",
    "            \n",
    "            txtname = name + '.txt'\n",
    "            c_id = get_character_id(name_movie2[name], name)\n",
    "            put_character(db, _id=c_id, movie = name_movie2[name],character=name, personality=json_parser(txtname))\n",
    "        \n",
    "        for doc in search_movie('the lord of the rings'):\n",
    "            print (doc['personality'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"session_id\": \"65ffa3a6-dcfa-486b-bbfb-2e32f77ec14a\"\n",
      "}\n",
      "Elmo: What would be the most amazing adventure to go on?\n",
      "Me: switch movie the lord of the rings\n",
      "Elmo: Bingo! this is it.\n",
      "Me: coding\n",
      "Elmo: What would be your first question after waking up from being cryogenically frozen for 100 years?\n",
      "Me: history.append(msg)\n",
      "Elmo: What’s your favorite genre of book or movie?\n",
      "Me: coding\n",
      "Elmo: What do you wish you knew more about?\n",
      "Me: coding\n",
      "Elmo: What would be your ideal way to spend the weekend?\n",
      "Me: coding\n",
      "Elmo: What’s the best single day on the calendar?\n",
      "Me: coding\n",
      "Elmo: I didn't understand. You can try rephrasing.\n",
      "Me: coding\n",
      "Elmo: What shows are you into?\n",
      "Me: coding\n",
      "Elmo: If you had unlimited funds to build a house that you would live in for the rest of your life, what would the finished house be like?\n",
      "Me: coding\n",
      "Elmo: What takes up too much of your time?\n",
      "Me: coding\n",
      "Elmo: What state or country do you never want to go back to?\n",
      "Me: coding\n",
      "Elmo: Can you reword your statement? I'm not understanding.\n",
      "Me: match character\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'personality'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-62c097318c63>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    132\u001b[0m            \u001b[1;31m#parses through chatbot dictionary traits->percentiles to generate list of percentiles\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m                 \u001b[0mchatbot_dict\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'personality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'personality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'percentile'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mparsed\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'personality'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'children'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'personality'"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import print_function\n",
    "import json, uuid\n",
    "from ibm_watson import AssistantV2\n",
    "NUMBER_OF_TRAITS = 28\n",
    "\n",
    "def least_squares_matcher(chatbot_percentiles, list_of_percentiles,movie_characters):\n",
    "    least_squares = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "\n",
    "    print (len(list_of_percentiles))\n",
    "    while j < len(list_of_percentiles):\n",
    "        cur_least_square = 0\n",
    "        \n",
    "        while i < 10: \n",
    "            \n",
    "            diff = chatbot_percentiles[i] - list_of_percentiles[j][i]\n",
    "            square = diff * diff\n",
    "            cur_least_square += square\n",
    "            i += 1\n",
    "\n",
    "        least_squares.append(cur_least_square)\n",
    "        j += 1\n",
    "    \n",
    "\n",
    "    least_square_index = (least_squares.index(min(least_squares)))\n",
    "\n",
    "    return (movie_characters[least_square_index])\n",
    "        \n",
    "\n",
    "def load_credential(authfile = None):\n",
    "    if authfile == None:\n",
    "        authfile = 'ibm-credentials.env'\n",
    "\n",
    "    with open(authfile) as f:\n",
    "        cred = {}\n",
    "        for line in f:\n",
    "            parts = line.strip('\\r').strip('\\n').split(\"=\")\n",
    "\n",
    "            if len(parts) == 2:\n",
    "                cred[parts[0]] = parts[1]\n",
    "        return cred;\n",
    "\n",
    "    return None\n",
    "\n",
    "def create_elmo(credential):\n",
    "   # If service instance provides API key authentication\n",
    "   return AssistantV2(\n",
    "              version='2018-09-20',\n",
    "              # url is optional, and defaults to the URL below. Use the correct URL for your region.\n",
    "              url='https://gateway.watsonplatform.net/assistant/api',\n",
    "              iam_apikey=credential['ASSISTANT_IAM_APIKEY'])\n",
    "\n",
    "#########################\n",
    "# Sessions\n",
    "#########################\n",
    "def create_session(assistant, ass_id):\n",
    "    session = assistant.create_session(ass_id).get_result()\n",
    "    print(json.dumps(session, indent=2))\n",
    "    return session\n",
    "\n",
    "#########################\n",
    "# Message\n",
    "#########################\n",
    "def send_message(assistant, ass_id, sess_id, msg):\n",
    "    message = assistant.message(\n",
    "    ass_id,\n",
    "    sess_id,\n",
    "    input={'text': msg}, #'What\\'s the weather like?'},\n",
    "    context={'metadata': {'deployment': 'myDeployment'\n",
    "           }\n",
    "       }).get_result()\n",
    "   #print(json.dumps(message, indent=2))\n",
    "    return message['output']['generic'][0]['text']\n",
    "\n",
    "def delete_session(assistant, ass_id, sess_id):\n",
    "    return assistant.delete_session(ass_id, sess_id).get_result()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    credential = load_credential()\n",
    "    \n",
    "    if not credential:\n",
    "        pass\n",
    "\n",
    "    elmo = create_elmo(credential)\n",
    "    ass_id = \"70f87349-4762-41fb-a263-5dfc9626ad53\"\n",
    "    sess_id = create_session(elmo, ass_id)[\"session_id\"]\n",
    "\n",
    "    history = []\n",
    "    dialog = \"hello\"\n",
    "    msg = \"\"\n",
    "    movie = \"the-godfather\"\n",
    "    movie_characters = []\n",
    "\n",
    "   #CHATBOT STRUCTURES\n",
    "    chatbot_dict = {} #dictionary of traits->percentiles for user conversation with chatbot\n",
    "    chatbot_percentiles = []  #list of percentiles for user conversation with chatbot\n",
    "\n",
    "   #MOVIE CHARACTER STRUCTURES\n",
    "    list_of_dicts = []  #list of dictionaries of traits->percentiles (dictionary is for each character)\n",
    "    list_of_percentiles = []  #list of lists of percentiles (list is for each character)\n",
    "    smaller_list = [] #for parsing purposes\n",
    "    movie_characters = []\n",
    "\n",
    "\n",
    "    while not \"bye\" in msg.lower() and not \"see you\" in msg.lower():\n",
    "        msg = send_message(elmo, ass_id, sess_id, dialog)\n",
    "\n",
    "\n",
    "        if \"Bingo! this is it\" in msg:\n",
    "            movie = history[-1].split(\"movie\")[1].strip()\n",
    "            movie_characters = char_names(movie)\n",
    "            history.append(msg)\n",
    "            \n",
    "        \n",
    "        elif \"Character\" in msg or \"Match character\" in msg or \"Search character\" in msg:\n",
    "            if len(movie_characters)  == 0:\n",
    "                movie_characters = char_names(movie)\n",
    "\n",
    "            import json\n",
    "            import requests\n",
    "\n",
    "            headers = {'Content-Type': 'text/plain;charset=utf-8','Accept': 'application/json',}\n",
    "\n",
    "            params = (('version', '2017-10-13'),)\n",
    "\n",
    "            data = open('history.txt', 'rb').read()\n",
    "            response = requests.post('https://gateway.watsonplatform.net/personality-insights/api/v3/profile?version=2017-10-13', headers=headers, data=data, auth=('apikey', 'QoK4TRsFxHfWUW3d-_KV4DOujgALshtnrzPolJ6BY_Wk'))\n",
    "            parsed = json.loads(response.text)\n",
    "\n",
    "           #parses through chatbot dictionary traits->percentiles to generate list of percentiles \n",
    "            for i in range(len(parsed)-2):\n",
    "                chatbot_dict[(parsed['personality'][i]['name'])] = parsed['personality'][i]['percentile']\n",
    " \n",
    "            for j in (range(len(parsed['personality'][i]['children']))):\n",
    "               chatbot_dict[(parsed['personality'][i]['children'][j]['name'])] = parsed['personality'][i]['children'][j]['percentile']\n",
    "\n",
    "            for trait in chatbot_dict:\n",
    "                chatbot_percentiles.append(chatbot_dict[trait])\n",
    "            \n",
    "            for doc in search_movie(movie):\n",
    "                list_of_dicts.append(doc['personality'])\n",
    "\n",
    "            for item in list_of_dicts:\n",
    "                for trait in item:\n",
    "                    smaller_list.append(item[trait])  \n",
    "                list_of_percentiles.append(smaller_list)\n",
    "                smaller_list=[]\n",
    "            \n",
    "            print ('You are most like ')\n",
    "            msg = least_squares_matcher(chatbot_percentiles, list_of_percentiles,movie_characters)\n",
    "\n",
    "\n",
    "\n",
    "           # do the personal insights/api/v3/profile# find the best character\n",
    "        dialog = input(\"Elmo: %s\\nMe: \" %(msg.strip('\\r').strip('\\n')))\n",
    "        history.append(dialog)\n",
    "\n",
    "        file_name = 'history'+'.txt'\n",
    "        file = open(file_name,\"w\")\n",
    "        file.write(str(history))\n",
    "        file.close()\n",
    "\n",
    "    delete_session(elmo, ass_id, sess_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"session_id\": \"510e9965-5ef5-42db-bb5b-1173fe1d2532\"\n",
      "}\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'send_message' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-3e6641fd7c68>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m    \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m    \u001b[1;32mwhile\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m\"bye\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;34m\"see you\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m        \u001b[0mmsg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msend_message\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0melmo\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mass_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msess_id\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdialog\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m        \u001b[0mdialog\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Elmo: %s\\nMe: \"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstrip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'send_message' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
